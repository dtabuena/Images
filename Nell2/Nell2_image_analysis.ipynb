{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Images/blob/main/Nell2/Nell2_image_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuvFURZJqTKl",
        "outputId": "6aa4c5a0-3bcd-4eb4-abc3-8870bb5396ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-bioformats\n",
            "  Downloading python_bioformats-4.0.6-py3-none-any.whl (40.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 40.3 MB 1.9 MB/s \n",
            "\u001b[?25hCollecting future>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 43.0 MB/s \n",
            "\u001b[?25hCollecting boto3>=1.14.23\n",
            "  Downloading boto3-1.25.5-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 40.7 MB/s \n",
            "\u001b[?25hCollecting python-javabridge==4.0.3\n",
            "  Downloading python-javabridge-4.0.3.tar.gz (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.1 in /usr/local/lib/python3.7/dist-packages (from python-javabridge==4.0.3->python-bioformats) (1.21.6)\n",
            "Collecting botocore<1.29.0,>=1.28.5\n",
            "  Downloading botocore-1.28.5-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 33.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.5->boto3>=1.14.23->python-bioformats) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.0,>=1.28.5->boto3>=1.14.23->python-bioformats) (1.15.0)\n",
            "Building wheels for collected packages: python-javabridge, future\n",
            "  Building wheel for python-javabridge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-javabridge: filename=python_javabridge-4.0.3-cp37-cp37m-linux_x86_64.whl size=1628131 sha256=a831257edff0bac3718d72b7ad9382b1b2545698608ff71b199a23649ab61597\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/7e/91/01b1bd8d29b4323834feb5cfec49b857fb212e6efc74ce103c\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=f6da9d81c10266eb9d3d54c22813e7f7ac683fbe55624cc94968cd99ab57b4d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built python-javabridge future\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, python-javabridge, future, boto3, python-bioformats\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.25.5 botocore-1.28.5 future-0.18.2 jmespath-1.0.1 python-bioformats-4.0.6 python-javabridge-4.0.3 s3transfer-0.6.0 urllib3-1.26.12\n"
          ]
        }
      ],
      "source": [
        "!pip install python-bioformats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MEmlpvSqlsv",
        "outputId": "c8ad99f8-9a01-421e-c497-0e4a84acda68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/images.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            "replace /content/images/Nell2_08-04-22_DG_40X_2XZoom_1.oir? [y]es, [n]o, [A]ll, [N]one, [r]ename:  extracting: /content/images/Nell2_08-04-22_DG_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-09-22_DG_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-10-22_DG_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_CA3_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-09-22_CA3_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-10-22_CA3_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S001_DG_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S002_DG_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-10-22__S001_DG_40X_2XZoom_2.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S001_CA3_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S002_CA3_40X_2XZoom_1.oir  \n",
            " extracting: /content/images/Nell2_08-10-22__S001_CA3_40X_2XZoom_2.oir  \n",
            " extracting: /content/images/Nell2_08-09-22_DG_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-10-22_DG_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-09-22_CA3_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-10-22_CA3_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S001_DG_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S002_DG_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S001_CA3_40X_2XZoom_1_DAPIonly.oir  \n",
            " extracting: /content/images/Nell2_08-04-22_S002_CA3_40X_2XZoom_1_DAPIonly.oir  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import javabridge\n",
        "import bioformats\n",
        "import skimage\n",
        "from skimage import filters\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib\n",
        "import os\n",
        "import scipy\n",
        "from scipy import ndimage as ndi\n",
        "javabridge.start_vm(class_path=bioformats.JARS)\n",
        "\n",
        "\n",
        "\n",
        "def get_drobox_folder(link, new_filename):\n",
        "    'Download a folder from dropbox and unzip'\n",
        "    zipped_file_path = \"/content/\"+new_filename + \".zip\"\n",
        "    unzipped_file_path = \"/content/\"+new_filename\n",
        "    if not( os.path.exists(zipped_file_path)):\n",
        "        !wget -O $zipped_file_path $link    # download with new name\n",
        "    !echo A | unzip $zipped_file_path -d $unzipped_file_path \n",
        "    return new_filename\n",
        "\n",
        "def get_sub_files(rootdir):\n",
        "    'Recursively search subfolders and return a list of all files'\n",
        "    file_list =[]\n",
        "    for rootdir, dirs, files in os.walk(rootdir): \n",
        "            file_list.extend([os.path.join(rootdir,f) for f in files])\n",
        "    return file_list\n",
        "\n",
        "\n",
        "data_drop_folder = 'https://www.dropbox.com/sh/dbuo3g9pd598xmw/AABx6mF-MN7Pyhr4xZWmOfWka?dl=0' # NELL2\n",
        "\n",
        "folder = get_drobox_folder(data_drop_folder, 'images')\n",
        "file_list = get_sub_files(folder)\n",
        "file_list.sort()\n",
        "file_list = [f for f in file_list if 'DAPI' not in f]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CELLPOSE_LOCAL_MODELS_PATH\"] = \"/PATH_FOR_MODELS/\"\n",
        "\n",
        "!pip install cellpose\n",
        "from cellpose import models"
      ],
      "metadata": {
        "id": "ryJx-hnnOTnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(image_name):\n",
        "    my_reader = bioformats.get_image_reader('my_image', image_name)\n",
        "\n",
        "    c_dim = my_reader.rdr.getSizeC()\n",
        "    z_dim = my_reader.rdr.getSizeZ()\n",
        "    x_dim = my_reader.rdr.getSizeX()\n",
        "    y_dim = my_reader.rdr.getSizeY()\n",
        "    # print(x_dim,y_dim,c_dim,z_dim)\n",
        "\n",
        "    image = np.empty([x_dim,y_dim,c_dim,z_dim])\n",
        "    for zi in range(z_dim):\n",
        "        img_zi = my_reader.read(c=None, z=zi,rescale=True)\n",
        "        image[:,:,:,zi] = img_zi\n",
        "\n",
        "    for ci in range(image.shape[2]):\n",
        "        cim = image[:,:,ci,:]\n",
        "        flat = cim.flatten()\n",
        "        max= np.percentile(flat,100)\n",
        "        assert max>0 , print(flat)\n",
        "        cim = cim/max\n",
        "        image[:,:,ci,:] = cim\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "gIRc5isuTmbK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vG4Oef9rQMr",
        "outputId": "a1e4cd41-f57c-47e7-9311-198d84835b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cellpose in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from cellpose) (0.39.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from cellpose) (5.5.0)\n",
            "Requirement already satisfied: fastremap in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.13.3)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.7/dist-packages (from cellpose) (2021.11.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cellpose) (4.64.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from cellpose) (4.6.0.66)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from cellpose) (2021.11.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.12.1+cu113)\n",
            "Requirement already satisfied: numba>=0.53.0 in /usr/local/lib/python3.7/dist-packages (from cellpose) (0.56.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.0->cellpose) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.0->cellpose) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->cellpose) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.53.0->cellpose) (3.10.0)\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def score_image(image,chan_dim,cell_chan):\n",
        "chan_dim = 2\n",
        "cell_chan = 2\n",
        "z_dim = 3\n",
        "diameter = 30\n",
        "min_vox = 500\n",
        "ch_names = ['target','mCherry','NeuN']\n",
        "\n",
        "\n",
        "def norm_channels(image,chan_dim,z_dim,):\n",
        "    '''Transpose ndims, preserve labels'''\n",
        "    dim_order = np.arange(image.ndim).tolist()\n",
        "    dim_order = [chan_dim, z_dim] + [d for d in dim_order if d not in [chan_dim, z_dim]]\n",
        "    chan_dim = [i for i in range(len(dim_order)) if dim_order[i]==chan_dim][0]\n",
        "    z_dim = [i for i in range(len(dim_order)) if dim_order[i]==z_dim][0]\n",
        "\n",
        "    '''Normalize channel intensities'''\n",
        "    image_r=np.transpose(image.copy(),dim_order)\n",
        "    ch_val_list = []\n",
        "    for ch in range(image_r.shape[chan_dim]):    \n",
        "        ch_val = image_r[ch,:,:,:].copy()\n",
        "        for zi in range(image_r.shape[z_dim]):\n",
        "            ch_val_z = ch_val[zi,:,:]\n",
        "            ch_val_z = (ch_val_z-np.mean(ch_val_z.flatten())) / np.std(ch_val_z.flatten()) # zscore\n",
        "            ch_val_z = (ch_val_z) / np.std(ch_val_z.flatten())\n",
        "            ch_val[zi,:,:] = ch_val_z\n",
        "        ch_val_list.append(ch_val)\n",
        "    image_znorm = np.stack(ch_val_list,axis=0)\n",
        "    return image_znorm, image_r,chan_dim,z_dim\n",
        "\n",
        "def mask_image_cellpose(image_r,cell_chan,diameter,exp_dist):\n",
        "    '''Generate Masks with Cellpose'''\n",
        "    model = models.Cellpose(model_type='cyto')\n",
        "    masks, _, _, _ = model.eval(image_r[cell_chan,:,:,:], diameter=diameter, channels=[0,0], stitch_threshold=.001,do_3D=False)\n",
        "    masks=masks.astype(float)\n",
        "    exp_masks = masks.copy()\n",
        "    for zi in range(masks.shape[0]):\n",
        "        exp_masks[zi,:,:] = skimage.segmentation.expand_labels(exp_masks[zi,:,:], distance=exp_dist)\n",
        "    return masks, exp_masks\n",
        "\n",
        "\n",
        "def quant_cells(image_znorm, image_r, exp_masks,chan_dim):\n",
        "    '''Quantify Cell Intensities'''\n",
        "    cell_ids =np.arange(0,np.nanmax(exp_masks.flatten()))+1\n",
        "    cell_df = pd.DataFrame({'cell_id':cell_ids}).set_index('cell_id')\n",
        "    for ch in range(image_znorm.shape[chan_dim]):\n",
        "        for cell in cell_df.index:\n",
        "            cell_df.at[cell,'size'] = np.nansum((exp_masks.flatten()==cell))\n",
        "            cell_df.at[cell,'mean_'+ch_names[ch]] = np.nansum( image_znorm[ch,:,:,:][exp_masks==cell]) / cell_df.loc[cell,'size']\n",
        "            cell_df.at[cell,'raw_mean_'+ch_names[ch]] = np.nansum( image_r[ch,:,:,:][exp_masks==cell]) / cell_df.loc[cell,'size']\n",
        "    \n",
        "    \n",
        "\n",
        "    return cell_df\n",
        "\n",
        "\n",
        "def calc_odd(cell_df,t):\n",
        "    '''Calculate Odds Ratios'''\n",
        "    is_green = cell_df['mean_target']>t\n",
        "    not_green = cell_df['mean_target']<=t\n",
        "    is_red = cell_df['mean_mCherry']>t\n",
        "    not_red = cell_df['mean_mCherry']<=t\n",
        "\n",
        "    p_G_nR = np.mean(  is_green[not_red]  )\n",
        "    p_G_iR = np.mean(  is_green[is_red]  )\n",
        "    # print('P(G|~R)',p_G_nR)\n",
        "    # print('P(G|R)',p_G_iR)\n",
        "\n",
        "    p_R_iG = np.mean(  is_red[is_green]  )\n",
        "    p_R_nG = np.mean(  is_red[not_green]  )\n",
        "    # print('P(R|G)',p_R_iG)\n",
        "    # print('P(R|~G)',p_R_nG)\n",
        "\n",
        "    num_RnG = np.sum(is_red[not_green] )\n",
        "    num_nRnG = np.sum(not_red[not_green] )\n",
        "    num_RG = np.sum(is_red[is_green] )\n",
        "    num_nRG = np.sum(not_red[is_green] )\n",
        "    OR = (num_RG * num_nRnG)/ (num_RnG * num_nRG)\n",
        "    # print('odds',OR)\n",
        "\n",
        "    targ_sig_nR = np.mean(cell_df['raw_mean_target'][cell_df['mean_mCherry']<t])\n",
        "    targ_sig_iR = np.mean(cell_df['raw_mean_target'][cell_df['mean_mCherry']>t])\n",
        "\n",
        "    results = {'OR':OR,\n",
        "               'num_RnG':num_RnG,\n",
        "               'num_nRnG':num_nRnG,\n",
        "               'num_RG':num_RG,\n",
        "               'num_nRG':num_nRG,\n",
        "               'targ_sig_nR':targ_sig_nR,\n",
        "               'targ_sig_iR':targ_sig_iR}\n",
        "\n",
        "    cell_df['Pos']=cell_df['mean_mCherry']>t\n",
        "    mean_target_negative = np.mean(cell_df['raw_mean_target'][np.logical_not(cell_df['Pos'].values)])\n",
        "    cell_df['target_norm'] = cell_df['raw_mean_target'] / mean_target_negative\n",
        "    cell_df['target_norm_NEG'] = cell_df['target_norm'][np.logical_not(cell_df['Pos'].values)]\n",
        "    cell_df['target_norm_POS'] = cell_df['target_norm'][cell_df['Pos']]\n",
        "\n",
        "    results=pd.DataFrame(data=results,index=[0])\n",
        "\n",
        "\n",
        "    return results, cell_df\n",
        "\n",
        "\n",
        "\n",
        "def plot_sample(fov,inset_xy,pxl_per_um=800/159.1,title=None):\n",
        "    sb_x = 195\n",
        "    sb_y = 4\n",
        "    sb_x = 780\n",
        "    sb_y = 10\n",
        "\n",
        "    image_name= fov['image_name']\n",
        "    image_name= os.path.basename(fov['image_name']).split('.')[0]\n",
        "    potential_targets = ['MDGA2','Nell2','RNF182']\n",
        "    target_name = [t for t in potential_targets if t in image_name][0]\n",
        "    # print(target_name)\n",
        "\n",
        "    fig_sample, axs = plt.subplots(2,4,figsize=(24,12))\n",
        "    axs=axs.flatten()\n",
        "    axs[0].imshow(fov['image_znorm'][2,zi,:,:],cmap='gray',vmax=3)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "    axs[1].imshow(fov['image_znorm'][1,zi,:,:],cmap=cmap, vmax=4)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "    axs[2].imshow(fov['image_znorm'][0,zi,:,:],cmap=cmap,vmax=2)\n",
        "    w_sig = fov['image_znorm'][2,zi,:,:]\n",
        "    w_sig = w_sig+np.percentile(w_sig.flatten(),.1)\n",
        "    w_sig = w_sig/np.percentile(w_sig.flatten(),99.9)\n",
        "    w_chan = np.stack( [w_sig for i in range(3)] ,axis=-1)\n",
        "    r_sig = fov['image_znorm'][1,zi,:,:]\n",
        "    r_sig = r_sig+np.percentile(r_sig.flatten(),.0)\n",
        "    r_sig = r_sig/np.percentile(r_sig.flatten(),100)\n",
        "    r_chan = np.stack( [r_sig, np.zeros_like(r_sig), np.zeros_like(r_sig)],axis=-1)\n",
        "    g_sig = fov['image_znorm'][0,zi,:,:]\n",
        "    g_sig = g_sig-(np.percentile(g_sig.flatten(),0)*2)\n",
        "    g_sig = g_sig/(np.percentile(g_sig.flatten(),100)*1)\n",
        "    g_chan = np.stack( [ np.zeros_like(g_sig), g_sig, np.zeros_like(g_sig)],axis=-1)\n",
        "    gain = 2\n",
        "    merge = w_chan + r_chan + g_chan\n",
        "    axs[3].imshow(merge)\n",
        "\n",
        "\n",
        "    axs[0].text(10,790,'NeuN',color='w',fontsize=24)\n",
        "    axs[1].text(10,790,'mCherry',color=[1,0,0,1],fontsize=24)\n",
        "    axs[2].text(10,790,target_name,color=[0,1,0,1],fontsize=24)\n",
        "    # axs[3].text(0,800,'NeuN',color='w')\n",
        "\n",
        "    y1,y2,x1,x2, = inset_xy\n",
        "    my_rect = matplotlib.patches.Rectangle([y1,x1],  y2-y1, x2-x1,alpha=1, facecolor='none',edgecolor='c',linewidth=3)\n",
        "    axs[0].add_patch(my_rect)\n",
        "\n",
        "    # fig, axs = plt.subplots(1,4,figsize=(32,8))\n",
        "    # axs=axs.flatten()\n",
        "    axs[4].imshow(fov['image_znorm'][2,zi,x1:x2,y1:y2],cmap='gray',vmax=3)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "    axs[5].imshow(fov['image_znorm'][1,zi,x1:x2,y1:y2],cmap=cmap, vmax=4)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "    axs[6].imshow(fov['image_znorm'][0,zi,x1:x2,y1:y2],cmap=cmap,vmax=2)\n",
        "    axs[7].imshow(merge[x1:x2,y1:y2,:])\n",
        "\n",
        "    for a in axs:\n",
        "        a.get_xaxis().set_visible(False)\n",
        "        a.get_yaxis().set_visible(False)\n",
        "    \n",
        "\n",
        "\n",
        "    pxl_per_um = 800/160\n",
        "    sb_x = merge.shape[1]*.975\n",
        "    sb_y = merge.shape[0]*.025\n",
        "    big_scale_bar = matplotlib.patches.Rectangle([sb_x,sb_y],   -25*pxl_per_um , 10, alpha=1, facecolor='w',edgecolor='w',linewidth=0)\n",
        "    axs[0].add_patch(big_scale_bar)\n",
        "    sb_x = (x2-x1)*.975\n",
        "    sb_y = (y2-y1)*.025\n",
        "    small_scale_bar = matplotlib.patches.Rectangle([sb_x,sb_y],   -5*pxl_per_um , 3, alpha=1, facecolor='w',edgecolor='w',linewidth=0)\n",
        "    axs[4].add_patch(small_scale_bar)\n",
        "    \n",
        "    if title is not None:\n",
        "        fig_sample.suptitle(title)\n",
        "    plt.tight_layout(pad=1.1)\n",
        "    plt.show()\n",
        "    fig_sample.savefig(image_name+'MergePlot.png')\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "def image_pipeline(image_name,chan_dim,cell_chan,z_dim,t=0):\n",
        "    try:\n",
        "        image = read_image(image_name)\n",
        "\n",
        "        if image.shape[chan_dim]==4:\n",
        "            image = combine_dapi_neun( image, chan_dim, ch_ind=[0,3], keep_ch=3,scalar = 0 )\n",
        "\n",
        "        image_znorm, image_r,chan_dim,z_dim = norm_channels(image,chan_dim,z_dim,)\n",
        "        diameter = 30\n",
        "        exp_dist = 5\n",
        "        masks, exp_masks = mask_image_cellpose(image_r,cell_chan,diameter,exp_dist)\n",
        "        cell_df = quant_cells(image_znorm, image_r, exp_masks,chan_dim)\n",
        "        results,cell_df = calc_odd(cell_df,t)\n",
        "        cur_image_name= os.path.basename(image_name).split('.')[0]\n",
        "        potential_targets = ['MDGA2','Nell2','RNF182']\n",
        "        target_name = [t for t in potential_targets if t in cur_image_name][0]\n",
        "        cell_df.to_csv( cur_image_name+'Cell_Stats.csv')\n",
        "\n",
        "        \n",
        "\n",
        "        fov_dict = {'image_name':image_name,\n",
        "                    'raw_image':image,\n",
        "                    'image_r':image_r,\n",
        "                    'image_znorm':image_znorm,\n",
        "                    'masks':masks,\n",
        "                    'exp_masks':exp_masks,\n",
        "                    'cell_df':cell_df,\n",
        "                    'results':results,\n",
        "                    }\n",
        "\n",
        "        inset_xy =  [150,350,0,200]\n",
        "        plot_sample(fov_dict,inset_xy)\n",
        "    except: print(image_name)\n",
        "    \n",
        "    return fov_dict\n"
      ],
      "metadata": {
        "id": "jb1tX1l1DeJH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# image = read_image(sub_file_list[0])\n",
        "ch_dim = 3\n",
        "def combine_dapi_neun( image_np, ch_dim, ch_ind=[0,3], keep_ch=3,scalar = 1 ):\n",
        "    image_np_new = image_np.copy()\n",
        "    new_ord = np.array([ch_dim]+[ci for ci in range(len(image_np.shape)) if ci not in [ch_dim]])\n",
        "    ord_key = np.argsort(new_ord)\n",
        "    image_np_new = image_np_new.transpose(new_ord)\n",
        "    \n",
        "    image_new_chan = image_np_new[keep_ch,:,:,:].copy()\n",
        "    drop_chan = [c for c in ch_ind if c not in [keep_ch]]\n",
        "    image_drop_chan =  image_np_new[drop_chan,:,:,:].copy()\n",
        "    image_new_chan = image_new_chan+image_drop_chan*scalar\n",
        "\n",
        "    image_np_new[keep_ch,:,:,:] = image_new_chan\n",
        "    all_keep = np.array([c for c in range(image_np_new.shape[0]) if c not in drop_chan])\n",
        "    image_np_new_dropped = image_np_new[all_keep,:,:,:]\n",
        "    image_np_new_unT = image_np_new_dropped.transpose(ord_key)\n",
        "    return image_np_new_unT\n",
        "# combine_dapi_neun( image, 2, ch_ind=[0,3], keep_ch=3 )"
      ],
      "metadata": {
        "id": "HaHqxyPqZeqE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "chan_dim = 2\n",
        "cell_chan = 2\n",
        "z_dim = 3\n",
        "diameter = 30\n",
        "exp_dist = 5\n",
        "\n",
        "\n",
        "file_index = [i for i in range(len(file_list)) if 'MDGA' in file_list[i]]\n",
        "sub_file_list = [file_list[i] for i in file_index]\n",
        "\n",
        "multi_image_results = {}\n",
        "for f in tqdm( sub_file_list):\n",
        "\n",
        "    \n",
        "    \n",
        "    fov_dict=image_pipeline(f,chan_dim,cell_chan,z_dim,t=1)\n",
        "\n",
        "\n",
        "    multi_image_results[f]=fov_dict\n",
        "\n",
        "X = [350,650,0,200]\n",
        "insert_list = [[350,650,600,799],\n",
        "               [350,450,500,700],\n",
        "               [150,350,0,200],\n",
        "               [150,350,0,200],\n",
        "               [150,350,0,200],\n",
        "               [150,350,0,200],\n",
        "               [150,350,0,200]]"
      ],
      "metadata": {
        "id": "wonptWCESVsz",
        "outputId": "bf611147-9c17-4267-b486-ae3ddf96ac7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(fov,inset_xy,pxl_per_um=800/159.1,title=None):\n",
        "    sb_x = 195\n",
        "    sb_y = 4\n",
        "    sb_x = 780\n",
        "    sb_y = 10\n",
        "\n",
        "    image_name= fov['image_name']\n",
        "    image_name= os.path.basename(fov['image_name']).split('.')[0]\n",
        "    potential_targets = ['MDGA2','Nell2','RNF182']\n",
        "    target_name = [t for t in potential_targets if t in image_name][0]\n",
        "    # print(target_name)\n",
        "\n",
        "    fig_sample, axs = plt.subplots(2,4,figsize=(24,12))\n",
        "    axs=axs.flatten()\n",
        "    axs[0].imshow(fov['image_znorm'][2,zi,:,:],cmap='gray',vmax=3)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "    axs[1].imshow(fov['image_znorm'][1,zi,:,:],cmap=cmap, vmax=4)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "    axs[2].imshow(fov['image_znorm'][0,zi,:,:],cmap=cmap,vmax=2)\n",
        "    w_sig = fov['image_znorm'][2,zi,:,:]\n",
        "    w_sig = w_sig+np.percentile(w_sig.flatten(),.1)\n",
        "    w_sig = w_sig/np.percentile(w_sig.flatten(),99.9)\n",
        "    w_chan = np.stack( [w_sig for i in range(3)] ,axis=-1)\n",
        "    r_sig = fov['image_znorm'][1,zi,:,:]\n",
        "    r_sig = r_sig+np.percentile(r_sig.flatten(),.0)\n",
        "    r_sig = r_sig/np.percentile(r_sig.flatten(),100)\n",
        "    r_chan = np.stack( [r_sig, np.zeros_like(r_sig), np.zeros_like(r_sig)],axis=-1)\n",
        "    g_sig = fov['image_znorm'][0,zi,:,:]\n",
        "    g_sig = g_sig-(np.percentile(g_sig.flatten(),0)*2)\n",
        "    g_sig = g_sig/(np.percentile(g_sig.flatten(),100)*1)\n",
        "    g_chan = np.stack( [ np.zeros_like(g_sig), g_sig, np.zeros_like(g_sig)],axis=-1)\n",
        "    gain = 2\n",
        "    merge = w_chan + r_chan + g_chan\n",
        "    axs[3].imshow(merge)\n",
        "\n",
        "\n",
        "    axs[0].text(10,790,'NeuN',color='w',fontsize=24)\n",
        "    axs[1].text(10,790,'mCherry',color=[1,0,0,1],fontsize=24)\n",
        "    axs[2].text(10,790,target_name,color=[0,1,0,1],fontsize=24)\n",
        "    # axs[3].text(0,800,'NeuN',color='w')\n",
        "\n",
        "    y1,y2,x1,x2, = inset_xy\n",
        "    my_rect = matplotlib.patches.Rectangle([y1,x1],  y2-y1, x2-x1,alpha=1, facecolor='none',edgecolor='c',linewidth=3)\n",
        "    axs[0].add_patch(my_rect)\n",
        "\n",
        "    # fig, axs = plt.subplots(1,4,figsize=(32,8))\n",
        "    # axs=axs.flatten()\n",
        "    axs[4].imshow(fov['image_znorm'][2,zi,x1:x2,y1:y2],cmap='gray',vmax=3)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "    axs[5].imshow(fov['image_znorm'][1,zi,x1:x2,y1:y2],cmap=cmap, vmax=4)\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "    axs[6].imshow(fov['image_znorm'][0,zi,x1:x2,y1:y2],cmap=cmap,vmax=2)\n",
        "    axs[7].imshow(merge[x1:x2,y1:y2,:])\n",
        "\n",
        "    for a in axs:\n",
        "        a.get_xaxis().set_visible(False)\n",
        "        a.get_yaxis().set_visible(False)\n",
        "    \n",
        "\n",
        "\n",
        "    pxl_per_um = 800/160\n",
        "    sb_x = merge.shape[1]*.975\n",
        "    sb_y = merge.shape[0]*.025\n",
        "    big_scale_bar = matplotlib.patches.Rectangle([sb_x,sb_y],   -25*pxl_per_um , 10, alpha=1, facecolor='w',edgecolor='w',linewidth=0)\n",
        "    axs[0].add_patch(big_scale_bar)\n",
        "    sb_x = (x2-x1)*.975\n",
        "    sb_y = (y2-y1)*.025\n",
        "    small_scale_bar = matplotlib.patches.Rectangle([sb_x,sb_y],   -5*pxl_per_um , 3, alpha=1, facecolor='w',edgecolor='w',linewidth=0)\n",
        "    axs[4].add_patch(small_scale_bar)\n",
        "    \n",
        "    if title is not None:\n",
        "        fig_sample.suptitle(title)\n",
        "    plt.tight_layout() # pad=1.1\n",
        "    plt.show()\n",
        "    fig_sample.savefig(image_name+'MergePlot.png')\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "insert_list = [[100,300,200,400],\n",
        "               [350,550,400,600],\n",
        "               [400,600,300,500],\n",
        "            #    [150,350,0,200],\n",
        "            #    [150,350,0,200],\n",
        "            #    [150,350,0,200],\n",
        "            #    [150,350,0,200]\n",
        "               ]\n",
        "\n",
        "# insert_dict = {key:value for (key,value) in multi_image_results.keys()}\n",
        "\n",
        "for f_i in  range(len(multi_image_results.items())):\n",
        "    fov = multi_image_results[list(multi_image_results.keys())[f_i]]\n",
        "    inset_xy = insert_list[f_i]\n",
        "    plot_sample(fov,inset_xy,title=fov['image_name'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "H7p9eHWlsr5D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_image_results.keys()"
      ],
      "metadata": {
        "id": "zQNy5iZfR4aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50849cb4-cafd-466a-e3a3-0c239ff64dd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(3,4))\n",
        "\n",
        "targ_nR_list = []\n",
        "targ_iR_list = []\n",
        "for im_i in multi_image_results.keys():\n",
        "    print( multi_image_results[im_i]['results'])\n",
        "    targ_nR_list.append(   multi_image_results[im_i]['results']['targ_sig_nR'] )\n",
        "    targ_iR_list.append(   multi_image_results[im_i]['results']['targ_sig_iR'] )\n",
        "\n",
        "targ_iR_list = np.array(targ_iR_list)/np.array(targ_nR_list)\n",
        "targ_nR_list = np.array(targ_nR_list)/np.array(targ_nR_list)\n",
        "\n",
        "\n",
        "ax.bar(0,np.mean(targ_nR_list),zorder = 0,color='k',yerr=scipy.stats.sem(targ_nR_list))\n",
        "ax.bar(1,np.mean(targ_iR_list),zorder = 0,color='r',yerr=scipy.stats.sem(targ_iR_list))\n",
        "ax.scatter(np.zeros_like(targ_nR_list),targ_nR_list,zorder = 1,edgecolor='k',facecolor='w')\n",
        "ax.scatter(np.ones_like(targ_iR_list),targ_iR_list,zorder = 1,edgecolor='r',facecolor='w')\n",
        "\n",
        "ax.set_xticks([0,1])\n",
        "ax.set_xticklabels(['-' , '+'])\n",
        "ax.set_xlabel('mCherry')\n",
        "ax.set_ylabel('MDGA2 Intensity (AU)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1lUe5Avyb6ca",
        "outputId": "8728b935-7dbc-4b62-9179-07940c4fde7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims, where=where)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
            "  subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_image_results[0].keys()"
      ],
      "metadata": {
        "id": "g_GeuW6yuhA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "300ecc71-a211-47d9-f726-17c0bbfc1d04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-772968bf7020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmulti_image_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import colab\n",
        "\n",
        "for k in multi_image_results.keys():\n",
        "    multi_image_results[k]['cell_df']['Pos']=multi_image_results[k]['cell_df']['mean_mCherry']>1\n",
        "    image_name = str(k).split('.')[0]\n",
        "    multi_image_results[k]['cell_df'].to_csv(image_name + '_cell_stats.csv' )\n",
        "\n",
        "for path, directories, files in os.walk('images'):\n",
        "    for f in files:\n",
        "        if '.csv' in f:\n",
        "            print(f)\n",
        "            colab.files.download( os.path.join('images',f))\n",
        "\n"
      ],
      "metadata": {
        "id": "FanVQAUyuW3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t =1\n",
        "\n",
        "# from matplotlib.projections.polar import Axes\n",
        "fov = multi_image_results[1]\n",
        "zi = 9\n",
        "sp_size =16\n",
        "fig, axs = plt.subplots(2,2,figsize=(sp_size,sp_size))\n",
        "axs =axs.flatten()\n",
        "axs[0].imshow(fov['image_znorm'][2,zi,:,:],cmap='gray',vmax=3)\n",
        "axs[0].contour(fov['exp_masks'][zi,:,:],cmap='prism')\n",
        "\n",
        "\n",
        "axs[1].imshow(fov['masks'][zi,:,:]>0)\n",
        "axs[1].contour(fov['exp_masks'][zi,:,:],cmap='prism')\n",
        "\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "axs[2].imshow(fov['image_znorm'][1,zi,:,:],cmap=cmap, vmax=4)\n",
        "axs[2].contour(fov['exp_masks'][zi,:,:],cmap='prism')\n",
        "\n",
        "\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "axs[3].imshow(fov['image_znorm'][0,zi,:,:],cmap=cmap,vmin=-1, vmax=3)\n",
        "axs[3].contour(fov['exp_masks'][zi,:,:],cmap='prism')\n",
        "\n",
        "\n",
        "sp_size =4\n",
        "n=4\n",
        "cell_df = fov['cell_df']\n",
        "fig, ax = plt.subplots(1,n,figsize=(n*sp_size,sp_size))\n",
        "ax=ax.flatten()\n",
        "_=ax[0].hist(cell_df['mean_mCherry'])\n",
        "ax[0].set_xlabel('mCherry (z)')\n",
        "ax[0].set_ylabel('Cells (#)')\n",
        "\n",
        "_=ax[1].hist(cell_df['mean_target'])\n",
        "ax[1].set_xlabel('Target (z)')\n",
        "ax[1].set_ylabel('Cells (#)')\n",
        "\n",
        "ax[2].scatter(cell_df['mean_mCherry'],cell_df['mean_target'])\n",
        "ax[2].set_xlabel('mCherry (z)')\n",
        "ax[2].set_ylabel('Target (z)')\n",
        "\n",
        "\n",
        "vals=[cell_df['raw_mean_target'][cell_df['mean_mCherry']<t],\n",
        "      cell_df['raw_mean_target'][cell_df['mean_mCherry']>t]]\n",
        "means = [np.mean(v) for v in vals]\n",
        "errors = [np.std(v)/np.sqrt(v.size) for v in vals]\n",
        "\n",
        "\n",
        "ax[3].bar([0,1],means,yerr=errors)\n",
        "ax[3].set_xticks([0,1])\n",
        "ax[3].set_xticklabels(['Negative','Positive'])\n",
        "ax[3].set_xlabel('mCherry')\n",
        "ax[3].set_ylabel('Target Intensity (AU)')\n",
        "# ax[3].set_xticks()\n",
        "# ax[3].title.set_text('mean_NeuN')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mx6OuMeCcxw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_sample, axs = plt.subplots(2,4,figsize=(24,12))\n",
        "axs=axs.flatten()\n",
        "axs[0].imshow(fov['image_znorm'][2,zi,:,:],cmap='gray',vmax=3)\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "axs[1].imshow(fov['image_znorm'][1,zi,:,:],cmap=cmap, vmax=4)\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "axs[2].imshow(fov['image_znorm'][0,zi,:,:],cmap=cmap,vmax=2)\n",
        "w_sig = fov['image_znorm'][2,zi,:,:]\n",
        "w_sig = w_sig+np.percentile(w_sig.flatten(),.1)\n",
        "w_sig = w_sig/np.percentile(w_sig.flatten(),99.9)\n",
        "w_chan = np.stack( [w_sig for i in range(3)] ,axis=-1)\n",
        "r_sig = fov['image_znorm'][1,zi,:,:]\n",
        "r_sig = r_sig+np.percentile(r_sig.flatten(),.0)\n",
        "r_sig = r_sig/np.percentile(r_sig.flatten(),100)\n",
        "r_chan = np.stack( [r_sig, np.zeros_like(r_sig), np.zeros_like(r_sig)],axis=-1)\n",
        "g_sig = fov['image_znorm'][0,zi,:,:]\n",
        "g_sig = g_sig-(np.percentile(g_sig.flatten(),0)*2)\n",
        "g_sig = g_sig/(np.percentile(g_sig.flatten(),100)*1)\n",
        "g_chan = np.stack( [ np.zeros_like(g_sig), g_sig, np.zeros_like(g_sig)],axis=-1)\n",
        "gain = 2\n",
        "merge = w_chan + r_chan + g_chan\n",
        "axs[3].imshow(merge)\n",
        "\n",
        "\n",
        "axs[0].text(10,790,'NeuN',color='w',fontsize=24)\n",
        "axs[1].text(10,790,'mCherry',color=[1,0,0,1],fontsize=24)\n",
        "axs[2].text(10,790,'MDGA2',color=[0,1,0,1],fontsize=24)\n",
        "# axs[3].text(0,800,'NeuN',color='w')\n",
        "\n",
        "\n",
        "y1,y2,x1,x2, = [150,350,0,200,]\n",
        "\n",
        "my_rect = matplotlib.patches.Rectangle([y1,x1],  y2-y1, x2-x1,alpha=1, facecolor='none',edgecolor='c',linewidth=3)\n",
        "axs[0].add_patch(my_rect)\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(1,4,figsize=(32,8))\n",
        "# axs=axs.flatten()\n",
        "axs[4].imshow(fov['image_znorm'][2,zi,x1:x2,y1:y2],cmap='gray',vmax=3)\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "axs[5].imshow(fov['image_znorm'][1,zi,x1:x2,y1:y2],cmap=cmap, vmax=4)\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
        "axs[6].imshow(fov['image_znorm'][0,zi,x1:x2,y1:y2],cmap=cmap,vmax=2)\n",
        "axs[7].imshow(merge[x1:x2,y1:y2,:])\n",
        "\n",
        "for a in axs:\n",
        "    a.get_xaxis().set_visible(False)\n",
        "    a.get_yaxis().set_visible(False)\n",
        "plt.tight_layout(pad=1.1)\n",
        "\n",
        "\n",
        "pxl_per_um = 800/160\n",
        "sb_x = 780\n",
        "sb_y = 10\n",
        "big_scale_bar = matplotlib.patches.Rectangle([sb_x,sb_y],   -25*pxl_per_um , 10, alpha=1, facecolor='w',edgecolor='w',linewidth=0)\n",
        "axs[0].add_patch(big_scale_bar)\n",
        "sb_x = 195\n",
        "sb_y = 4\n",
        "small_scale_bar = matplotlib.patches.Rectangle([sb_x,sb_y],   -5*pxl_per_um , 3, alpha=1, facecolor='w',edgecolor='w',linewidth=0)\n",
        "axs[4].add_patch(small_scale_bar)\n",
        "fig_sample.savefig('sample_MDGA2.png')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiG64AcM6_Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "inset_xy =  [150,350,0,200]\n",
        "plot_sample(fov,inset_xy)"
      ],
      "metadata": {
        "id": "cVGo9wAsnk_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_name= os.path.basename(fov['image_name']).split('.')[0]\n",
        "potential_targets = ['MDGA2','Nell2','RNF182']\n",
        "target_name = [t for t in potential_targets if t in image_name][0]\n",
        "print(target_name)"
      ],
      "metadata": {
        "id": "tAaj5bSmnwNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_size = 8\n",
        "\n",
        "t = 1\n",
        "for zi in range(16):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(sp_size*2,sp_size))\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"red\"])\n",
        "    axs[0].imshow(fov['image_znorm'][1,zi,:,:],cmap=cmap, vmax=4)\n",
        "    axs[0].contour(fov['exp_masks'][zi,:,:],cmap='prism')\n",
        "    pos_neg_mask = fov['exp_masks'].copy()\n",
        "    pos_cells = cell_df.index[cell_df['mean_mCherry']>t]\n",
        "    # pos_neg_mask[pos_neg_mask==0]=np.nan\n",
        "    pos_neg_mask = pos_neg_mask*-1\n",
        "    for c in tqdm( pos_cells.values) :\n",
        "        pos_neg_mask[pos_neg_mask==-c]=1.\n",
        "    pos_neg_mask = (pos_neg_mask>0)*1.\n",
        "    pos_neg_mask[fov['exp_masks']==0]=-1\n",
        "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"black\",\"red\"])\n",
        "    axs[1].imshow(pos_neg_mask[zi,:,:],cmap=cmap)\n",
        "    axs[1].contour(fov['exp_masks'][zi,:,:],cmap='prism')\n"
      ],
      "metadata": {
        "id": "B4_aeMHOp1T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multi_image_results[0]['results'])"
      ],
      "metadata": {
        "id": "89DqrsK_ueWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from google import colab\n",
        "sub_f = 'data'\n",
        "zip_name = sub_f+'.zip'\n",
        "try: os.makedirs(sub_f)\n",
        "except: None\n",
        "try: hf.close()\n",
        "except: None\n",
        "for f in multi_image_results:\n",
        "    image_name_loc = f['image_name']\n",
        "    h5_name = os.path.basename(image_name_loc).split('.')[0]\n",
        "    hf = h5py.File( sub_f+'/'+h5_name+'.h5', 'w')\n",
        "    for k,v in f.items():\n",
        "        hf.create_dataset(k, data=v)\n",
        "    hf.close()\n",
        "!zip -r $zip_name $sub_f\n",
        "colab.files.download(zip_name)\n"
      ],
      "metadata": {
        "id": "BhbM5is9ALGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPX5C-UClt6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyi8azxcHv7NqPh1ZA/Fiz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}